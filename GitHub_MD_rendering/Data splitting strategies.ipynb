{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat? Data splitting strategies.\\n\\nThe two main techniques are:\\n[1] Evalaute models with train and split\\n[2] k-fold cross validation\\n\\nDate: 28/11/20\\nReference: XGBosst with python, Jason Brownlee\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What? Data splitting strategies.\n",
    "\n",
    "The 3 main techniques are:\n",
    "    [1] evalaute models with train and split\n",
    "    [2] k-fold cross validation\n",
    "    [3] stratified k-fold cross validation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = loadtxt('../DATASETS/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "# split data into X and y\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model with train & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.02%\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7) \n",
    "\n",
    "# fit model on training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCompared to the classical train & split approach the algortihm performance\\nare evaluated with less variance. It works by splitting the dataset into \\nk-parts (e.g. k = 5 or k = 10). Each split of the data is called a fold.\\nThe algorithm is trained on k − 1 folds with one held back and tested on \\nthe held back fold. This is repeated so that each fold of the dataset is \\ngiven a chance to be the held back test set. The results you get are averaged.\\nThis the best option you have when you do not have much data.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compared to the classical train & split approach the algortihm performance\n",
    "are evaluated with less variance. It works by splitting the dataset into \n",
    "k-parts (e.g. k = 5 or k = 10). Each split of the data is called a fold.\n",
    "The algorithm is trained on k − 1 folds with one held back and tested on \n",
    "the held back fold. This is repeated so that each fold of the dataset is \n",
    "given a chance to be the held back test set. The results you get are averaged.\n",
    "This the best option you have when you do not have much data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  72.52563226247437\n",
      "Standard deviation:  5.469806031642198\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "kfold = KFold(n_splits=10, shuffle = True, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \", results.mean()*100 )\n",
    "print(\"Standard deviation: \", results.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model with stratified k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you have many classes or the classes are imbalanced, it can be a good\n",
    "idea to use stratified folds. This has the effect of enforcing the same\n",
    "distribution of classes in each fold.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  74.21565276828434\n",
      "Standard deviation:  3.8262743861637145\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle = True, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \", results.mean()*100 )\n",
    "print(\"Standard deviation: \", results.std()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
