{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** XGBoost hyperparameters\n",
    "    \n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Classification problem \n",
    "- has heart desease = **1**\n",
    "- does not have heart desease = **0**\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
""      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../DATASETS/heart_disease.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain a baseline score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We'll use two diffrerent ways to split the data. The second strategy, i.e. stratified fold, includes the\n",
    "same percentage of target values in each fold.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.84 0.85 0.82 0.8  0.77]\n",
      "Accuracy mean: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    165\n",
       "True     138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.iloc[:, -1]==0.0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The dataset are a bit unbalance and the a stratified approach may be a better option. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.72 0.82 0.75 0.8  0.82]\n",
      "Accuracy mean: 0.78\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "# Obtain scores of cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "# Display accuracy\n",
    "print('Accuracy:', np.round(scores, 2))\n",
    "# Display mean accuracy\n",
    "print('Accuracy mean: %0.2f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **The score has gone down. What does this mean?** It's important not to become too invested in obtaining the highest possible score. In this case, we trained \n",
    "the same XGBClassifier model on different folds and obtained different scores. This shows the importance of\n",
    "being consistent with test folds when training models, and why the score is not necessarily the most important\n",
    "thing. \n",
    "- Although when choosing between models, obtaining the best possible score is an optimal strategy, the \n",
    "difference in scores here reveals that the model is not necessarily better. In this case, the two models have \n",
    "the same hyperparameters, and the difference in scores is attributed to the different folds.\n",
    "- The point here is to use the same folds to obtain new scores when fine-tuning hyperparameters\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **GridSearchCV** searches all possible combinations in a hyperparameter grid to find the best results. \n",
    "- **RandomizedSearchCV** selects 10 random hyperparameter combinations by default. You can change this by utsing the `n_iter` parameter. RandomizedSearchCV is typically used when GridSearchCV becomes unwieldy because there are too many hyperparameter combinations\n",
    "to exhaustively check each one.  \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, random=False): \n",
    "    \n",
    "    # Create model\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)    \n",
    "    # Create folds -> take of sample subdivision to get average\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    \n",
    "    # Chose the values to be searched in each folder selected above\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1, random_state=2)\n",
    "    else:\n",
    "        # Instantiate GridSearchCV as grid_reg\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    # Fit grid_reg on X_train and y_train\n",
    "    grid.fit(X, y)\n",
    "    # Extract best params\n",
    "    best_params = grid.best_params_\n",
    "    # Print best params\n",
    "    print(\"Best params:\", best_params)    \n",
    "    # Compute best score\n",
    "    best_score = grid.best_score_\n",
    "    # Print best score\n",
    "    print(\"Best score: {:.5f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  What followa is a **change-one-but-keep-others-constant** approach.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 100}\n",
      "Best score: 0.78235\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.05}\n",
      "Best score: 0.79585\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 2}\n",
      "Best score: 0.79902\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 0.5}\n",
      "Best score: 0.79574\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'gamma':[0, 0.01, 0.1, 0.5, 1, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_child_weight': 5}\n",
      "Best score: 0.81219\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.8}\n",
      "Best score: 0.79579\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.7}\n",
      "Best score: 0.79902\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Early stopping provides a limit to the number of rounds that iterative machine learning algorithms train on.\n",
    "commonly 'error' for classification, and 'rmse' for regression. \n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.15790\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "[2]\tvalidation_0-error:0.11842\n",
      "[3]\tvalidation_0-error:0.13158\n",
      "[4]\tvalidation_0-error:0.11842\n",
      "[5]\tvalidation_0-error:0.14474\n",
      "[6]\tvalidation_0-error:0.14474\n",
      "[7]\tvalidation_0-error:0.14474\n",
      "[8]\tvalidation_0-error:0.14474\n",
      "[9]\tvalidation_0-error:0.14474\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.15790\n",
      "[12]\tvalidation_0-error:0.15790\n",
      "[13]\tvalidation_0-error:0.17105\n",
      "[14]\tvalidation_0-error:0.17105\n",
      "[15]\tvalidation_0-error:0.17105\n",
      "[16]\tvalidation_0-error:0.15790\n",
      "[17]\tvalidation_0-error:0.17105\n",
      "[18]\tvalidation_0-error:0.15790\n",
      "[19]\tvalidation_0-error:0.17105\n",
      "[20]\tvalidation_0-error:0.17105\n",
      "[21]\tvalidation_0-error:0.17105\n",
      "[22]\tvalidation_0-error:0.18421\n",
      "[23]\tvalidation_0-error:0.18421\n",
      "[24]\tvalidation_0-error:0.17105\n",
      "[25]\tvalidation_0-error:0.18421\n",
      "[26]\tvalidation_0-error:0.18421\n",
      "[27]\tvalidation_0-error:0.18421\n",
      "[28]\tvalidation_0-error:0.18421\n",
      "[29]\tvalidation_0-error:0.18421\n",
      "[30]\tvalidation_0-error:0.18421\n",
      "[31]\tvalidation_0-error:0.18421\n",
      "[32]\tvalidation_0-error:0.18421\n",
      "[33]\tvalidation_0-error:0.18421\n",
      "[34]\tvalidation_0-error:0.18421\n",
      "[35]\tvalidation_0-error:0.18421\n",
      "[36]\tvalidation_0-error:0.18421\n",
      "[37]\tvalidation_0-error:0.18421\n",
      "[38]\tvalidation_0-error:0.18421\n",
      "[39]\tvalidation_0-error:0.18421\n",
      "[40]\tvalidation_0-error:0.18421\n",
      "[41]\tvalidation_0-error:0.18421\n",
      "[42]\tvalidation_0-error:0.18421\n",
      "[43]\tvalidation_0-error:0.17105\n",
      "[44]\tvalidation_0-error:0.18421\n",
      "[45]\tvalidation_0-error:0.17105\n",
      "[46]\tvalidation_0-error:0.18421\n",
      "[47]\tvalidation_0-error:0.18421\n",
      "[48]\tvalidation_0-error:0.17105\n",
      "[49]\tvalidation_0-error:0.15790\n",
      "[50]\tvalidation_0-error:0.17105\n",
      "[51]\tvalidation_0-error:0.17105\n",
      "[52]\tvalidation_0-error:0.15790\n",
      "[53]\tvalidation_0-error:0.17105\n",
      "[54]\tvalidation_0-error:0.17105\n",
      "[55]\tvalidation_0-error:0.17105\n",
      "[56]\tvalidation_0-error:0.17105\n",
      "[57]\tvalidation_0-error:0.17105\n",
      "[58]\tvalidation_0-error:0.17105\n",
      "[59]\tvalidation_0-error:0.17105\n",
      "[60]\tvalidation_0-error:0.17105\n",
      "[61]\tvalidation_0-error:0.17105\n",
      "[62]\tvalidation_0-error:0.17105\n",
      "[63]\tvalidation_0-error:0.17105\n",
      "[64]\tvalidation_0-error:0.17105\n",
      "[65]\tvalidation_0-error:0.17105\n",
      "[66]\tvalidation_0-error:0.18421\n",
      "[67]\tvalidation_0-error:0.18421\n",
      "[68]\tvalidation_0-error:0.18421\n",
      "[69]\tvalidation_0-error:0.18421\n",
      "[70]\tvalidation_0-error:0.18421\n",
      "[71]\tvalidation_0-error:0.18421\n",
      "[72]\tvalidation_0-error:0.18421\n",
      "[73]\tvalidation_0-error:0.18421\n",
      "[74]\tvalidation_0-error:0.17105\n",
      "[75]\tvalidation_0-error:0.18421\n",
      "[76]\tvalidation_0-error:0.17105\n",
      "[77]\tvalidation_0-error:0.18421\n",
      "[78]\tvalidation_0-error:0.15790\n",
      "[79]\tvalidation_0-error:0.17105\n",
      "[80]\tvalidation_0-error:0.15790\n",
      "[81]\tvalidation_0-error:0.15790\n",
      "[82]\tvalidation_0-error:0.15790\n",
      "[83]\tvalidation_0-error:0.15790\n",
      "[84]\tvalidation_0-error:0.15790\n",
      "[85]\tvalidation_0-error:0.15790\n",
      "[86]\tvalidation_0-error:0.15790\n",
      "[87]\tvalidation_0-error:0.15790\n",
      "[88]\tvalidation_0-error:0.15790\n",
      "[89]\tvalidation_0-error:0.15790\n",
      "[90]\tvalidation_0-error:0.15790\n",
      "[91]\tvalidation_0-error:0.15790\n",
      "[92]\tvalidation_0-error:0.15790\n",
      "[93]\tvalidation_0-error:0.17105\n",
      "[94]\tvalidation_0-error:0.17105\n",
      "[95]\tvalidation_0-error:0.17105\n",
      "[96]\tvalidation_0-error:0.17105\n",
      "[97]\tvalidation_0-error:0.17105\n",
      "[98]\tvalidation_0-error:0.17105\n",
      "[99]\tvalidation_0-error:0.17105\n",
      "Accuracy: 82.89%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric='error'\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.15790\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "[2]\tvalidation_0-error:0.11842\n",
      "[3]\tvalidation_0-error:0.13158\n",
      "[4]\tvalidation_0-error:0.11842\n",
      "[5]\tvalidation_0-error:0.14474\n",
      "[6]\tvalidation_0-error:0.14474\n",
      "[7]\tvalidation_0-error:0.14474\n",
      "[8]\tvalidation_0-error:0.14474\n",
      "[9]\tvalidation_0-error:0.14474\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.15790\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "\n",
      "Accuracy: 89.47%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    booster='gbtree', objective='binary:logistic', random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric = \"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric,\n",
    "          eval_set=eval_set, early_stopping_rounds=10, verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.15790\n",
      "Will train until validation_0-error hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "[2]\tvalidation_0-error:0.11842\n",
      "[3]\tvalidation_0-error:0.13158\n",
      "[4]\tvalidation_0-error:0.11842\n",
      "[5]\tvalidation_0-error:0.14474\n",
      "[6]\tvalidation_0-error:0.14474\n",
      "[7]\tvalidation_0-error:0.14474\n",
      "[8]\tvalidation_0-error:0.14474\n",
      "[9]\tvalidation_0-error:0.14474\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.15790\n",
      "[12]\tvalidation_0-error:0.15790\n",
      "[13]\tvalidation_0-error:0.17105\n",
      "[14]\tvalidation_0-error:0.17105\n",
      "[15]\tvalidation_0-error:0.17105\n",
      "[16]\tvalidation_0-error:0.15790\n",
      "[17]\tvalidation_0-error:0.17105\n",
      "[18]\tvalidation_0-error:0.15790\n",
      "[19]\tvalidation_0-error:0.17105\n",
      "[20]\tvalidation_0-error:0.17105\n",
      "[21]\tvalidation_0-error:0.17105\n",
      "[22]\tvalidation_0-error:0.18421\n",
      "[23]\tvalidation_0-error:0.18421\n",
      "[24]\tvalidation_0-error:0.17105\n",
      "[25]\tvalidation_0-error:0.18421\n",
      "[26]\tvalidation_0-error:0.18421\n",
      "[27]\tvalidation_0-error:0.18421\n",
      "[28]\tvalidation_0-error:0.18421\n",
      "[29]\tvalidation_0-error:0.18421\n",
      "[30]\tvalidation_0-error:0.18421\n",
      "[31]\tvalidation_0-error:0.18421\n",
      "[32]\tvalidation_0-error:0.18421\n",
      "[33]\tvalidation_0-error:0.18421\n",
      "[34]\tvalidation_0-error:0.18421\n",
      "[35]\tvalidation_0-error:0.18421\n",
      "[36]\tvalidation_0-error:0.18421\n",
      "[37]\tvalidation_0-error:0.18421\n",
      "[38]\tvalidation_0-error:0.18421\n",
      "[39]\tvalidation_0-error:0.18421\n",
      "[40]\tvalidation_0-error:0.18421\n",
      "[41]\tvalidation_0-error:0.18421\n",
      "[42]\tvalidation_0-error:0.18421\n",
      "[43]\tvalidation_0-error:0.17105\n",
      "[44]\tvalidation_0-error:0.18421\n",
      "[45]\tvalidation_0-error:0.17105\n",
      "[46]\tvalidation_0-error:0.18421\n",
      "[47]\tvalidation_0-error:0.18421\n",
      "[48]\tvalidation_0-error:0.17105\n",
      "[49]\tvalidation_0-error:0.15790\n",
      "[50]\tvalidation_0-error:0.17105\n",
      "[51]\tvalidation_0-error:0.17105\n",
      "[52]\tvalidation_0-error:0.15790\n",
      "[53]\tvalidation_0-error:0.17105\n",
      "[54]\tvalidation_0-error:0.17105\n",
      "[55]\tvalidation_0-error:0.17105\n",
      "[56]\tvalidation_0-error:0.17105\n",
      "[57]\tvalidation_0-error:0.17105\n",
      "[58]\tvalidation_0-error:0.17105\n",
      "[59]\tvalidation_0-error:0.17105\n",
      "[60]\tvalidation_0-error:0.17105\n",
      "[61]\tvalidation_0-error:0.17105\n",
      "[62]\tvalidation_0-error:0.17105\n",
      "[63]\tvalidation_0-error:0.17105\n",
      "[64]\tvalidation_0-error:0.17105\n",
      "[65]\tvalidation_0-error:0.17105\n",
      "[66]\tvalidation_0-error:0.18421\n",
      "[67]\tvalidation_0-error:0.18421\n",
      "[68]\tvalidation_0-error:0.18421\n",
      "[69]\tvalidation_0-error:0.18421\n",
      "[70]\tvalidation_0-error:0.18421\n",
      "[71]\tvalidation_0-error:0.18421\n",
      "[72]\tvalidation_0-error:0.18421\n",
      "[73]\tvalidation_0-error:0.18421\n",
      "[74]\tvalidation_0-error:0.17105\n",
      "[75]\tvalidation_0-error:0.18421\n",
      "[76]\tvalidation_0-error:0.17105\n",
      "[77]\tvalidation_0-error:0.18421\n",
      "[78]\tvalidation_0-error:0.15790\n",
      "[79]\tvalidation_0-error:0.17105\n",
      "[80]\tvalidation_0-error:0.15790\n",
      "[81]\tvalidation_0-error:0.15790\n",
      "[82]\tvalidation_0-error:0.15790\n",
      "[83]\tvalidation_0-error:0.15790\n",
      "[84]\tvalidation_0-error:0.15790\n",
      "[85]\tvalidation_0-error:0.15790\n",
      "[86]\tvalidation_0-error:0.15790\n",
      "[87]\tvalidation_0-error:0.15790\n",
      "[88]\tvalidation_0-error:0.15790\n",
      "[89]\tvalidation_0-error:0.15790\n",
      "[90]\tvalidation_0-error:0.15790\n",
      "[91]\tvalidation_0-error:0.15790\n",
      "[92]\tvalidation_0-error:0.15790\n",
      "[93]\tvalidation_0-error:0.17105\n",
      "[94]\tvalidation_0-error:0.17105\n",
      "[95]\tvalidation_0-error:0.17105\n",
      "[96]\tvalidation_0-error:0.17105\n",
      "[97]\tvalidation_0-error:0.17105\n",
      "[98]\tvalidation_0-error:0.17105\n",
      "[99]\tvalidation_0-error:0.17105\n",
      "[100]\tvalidation_0-error:0.17105\n",
      "[101]\tvalidation_0-error:0.17105\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-error:0.10526\n",
      "\n",
      "Accuracy: 89.47%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=2, n_estimators=5000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric=\"error\"\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set, early_stopping_rounds=100)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 50}\n",
      "Best score: 0.78907\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'n_estimators':[2, 25, 50, 75, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'max_depth':[1, 2, 3, 4, 6, 7, 8], \n",
    "                    'n_estimators':[2, 50, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.3, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 1, 'n_estimators': 50, 'subsample': 1}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.5, 'max_depth': 2, 'min_child_weight': 4, 'n_estimators': 2, 'subsample': 0.9}\n",
      "Best score: 0.81224\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1, 2, 3, 4, 5], \n",
    "                    'n_estimators':[2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Up until now we have search on a change one and keep other constant basis via grid search.\n",
    "- By doing this we may have missed something. Now we'll switch to random search while allowing more than one hyperparmater to change.\n",
    "- This will improve our changes to find the best option.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.6, 'n_estimators': 25, 'min_child_weight': 4, 'max_depth': 4, 'learning_rate': 0.5}\n",
      "Best score: 0.82208\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'min_child_weight':[1, 2, 3, 4, 5], \n",
    "                    'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                    'max_depth':[1, 2, 3, 4, 5, None], \n",
    "                    'n_estimators':[2, 25, 50, 75, 100]}, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 1, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.83869\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.8, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.84852\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'colsample_bynode':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.9, 'colsample_bynode': 0.5, 'colsample_bytree': 0.8, 'gamma': 0, 'max_depth': 1, 'n_estimators': 50}\n",
      "Best score: 0.84852\n"
     ]
    }
   ],
   "source": [
    "grid_search(params={'gamma':[0, 0.01, 0.05, 0.1, 0.5, 1, 2, 3], \n",
    "                    'colsample_bylevel':[0.9], \n",
    "                    'colsample_bytree':[0.8], \n",
    "                    'colsample_bynode':[0.5], \n",
    "                    'max_depth':[1], \n",
    "                    'n_estimators':[50]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Reference: Corey Wade, Hands-On Gradient Boosting with XGBoost and scikit-learn\n",
    "- https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn\n",
    "    \n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
